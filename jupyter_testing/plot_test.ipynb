{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64209534-8576-4ed0-90a1-6fa7abaef70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select intepreter and change environment to anaconda\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib\n",
    "#import xmltodict\n",
    "from xml.dom import minidom\n",
    "import time\n",
    "\n",
    "\n",
    "#handles command line input parameter\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# testing file is from 10,000,000 reads, so mapping percentage is expected to be out of 10 mil\n",
    "blast_tsv_file = 'WT_APEX_TOMM20_4_S38_L004_R1_001_1mil_unmappedblast.tsv'\n",
    "blast_tsv_file2 = 'WT_APEX_TOMM20_4_S38_L004_R1_001_1mil_unmappedblast.tsv'\n",
    "piePath = 'Combined.png'\n",
    "piePathSample = os.path.splitext(piePath)[0]\n",
    "piePathSample2 = os.path.split(piePathSample)\n",
    "pieName = piePathSample2[1]\n",
    "\n",
    "#ncbi query functions\n",
    "def esearch(term, db='gds'):\n",
    "    \"\"\"\n",
    "    Queries NCBI using the esearch utility. GEO ('gds') database is used as default for search term.\n",
    "    \"\"\"\n",
    "    url = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db={db}&term={term}&retmax=5000&usehistory=y'\n",
    "    response = urllib.request.urlopen(url)\n",
    "    return response.read()\n",
    "\n",
    "\n",
    "def get_esummary(esearch_string, db='gds'):\n",
    "    \"\"\"\n",
    "    Parses a http response in XML format to obtain the webenv and querykey tokens.\n",
    "    Uses NCBI eutils to transform these tokens into web summaries of GEO (db='gds') datasets.\n",
    "    \"\"\"\n",
    "    xmldoc = minidom.parseString(esearch_string)\n",
    "    try:\n",
    "        webenv = xmldoc.getElementsByTagName('WebEnv')[0].firstChild.data\n",
    "        querykey = xmldoc.getElementsByTagName('QueryKey')[0].firstChild.data\n",
    "        host = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi'\n",
    "        params = f'?db={db}&version=2.0&query_key={querykey}&WebEnv={webenv}'\n",
    "        url = host + params\n",
    "        response = urllib.request.urlopen(url)\n",
    "        return response.read()\n",
    "    except IndexError as e:\n",
    "        print(f\"Unparsable publication string ({e}, search={esearch_string}\")\n",
    "        return \"\"\n",
    "\n",
    "#matplotlib to build the piechart\n",
    "fig, ((ax1, ax2, ax5), (ax3, ax4, ax6)) = plt.subplots(2, 3, figsize=(9, 5))\n",
    "fig.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "ax1.set_title('blastn piechart')\n",
    "ax2.set_title('blastn other')\n",
    "ax3.set_title('blastx piechart')\n",
    "ax4.set_title('blastx other')\n",
    "ax5.set_title('blastn percentage')\n",
    "ax6.set_title('blastx percentage')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Read the blast n file\n",
    "df = pd.read_csv(blast_tsv_file, header=None, sep='\\t')\n",
    "num_seqs = df.size\n",
    "df.columns = ['qseqid','sseqid','pident','length','mismatch','gapopen','qstart','qend','sstart','send','evalue','bitscore']\n",
    "\n",
    "df2 = df[['qseqid','sseqid','evalue']].copy()\n",
    "\n",
    "# Read the blast x file\n",
    "df4 = pd.read_csv(blast_tsv_file2, header=None, sep='\\t')\n",
    "num_seqs2 = df4.size\n",
    "df4.columns = ['qseqid','sseqid','pident','length','mismatch','gapopen','qstart','qend','sstart','send','evalue','bitscore']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### still need to reorganize the code for each different file below.\n",
    "\n",
    "\n",
    "#blast n output default is by best hit/lowest e value score, therefore add the first sseqid result for each qseqid\n",
    "sseqid_list1 = []\n",
    "qseqid_list1 = []\n",
    "for idx in df.index:\n",
    "        if df['qseqid'][idx] not in qseqid_list1:\n",
    "                qseqid_list1.append(df['qseqid'][idx])\n",
    "                sseqid_list1.append(df['sseqid'][idx])\n",
    "sseqid_np1 = np.array(sseqid_list1)\n",
    "\n",
    "#blast x output default is by best hit/lowest e value score, therefore add the first sseqid result for each qseqid\n",
    "sseqid_list2 = []\n",
    "qseqid_list2 = []\n",
    "for idx in df4.index:\n",
    "        if df4['qseqid'][idx] not in qseqid_list2:\n",
    "                qseqid_list2.append(df4['qseqid'][idx])\n",
    "                sseqid_list2.append(df4['sseqid'][idx])\n",
    "sseqid_np2 = np.array(sseqid_list2)\n",
    "\n",
    "df3 = pd.DataFrame(data = sseqid_np1, columns=['sseqid'])\n",
    "print(df3)\n",
    "\n",
    "df5 = pd.DataFrame(data = sseqid_np2, columns=['sseqid'])\n",
    "print(df5)\n",
    "\n",
    "sseq_count_series1 = df3['sseqid'].value_counts()\n",
    "print(sseq_count_series1)\n",
    "\n",
    "sseq_count_series4 = df5['sseqid'].value_counts()\n",
    "print(sseq_count_series4)\n",
    "\n",
    "#loop through series to determine which elements to remove and add into \"other\" column\n",
    "to_remove1 = []\n",
    "other_count1 = 0\n",
    "otherDict1 = {}\n",
    "to_remove2 = []\n",
    "other_count2 = 0\n",
    "otherDict2 = {}\n",
    "\n",
    "#blastn number mapped\n",
    "print(num_seqs)\n",
    "\n",
    "#blastx number mapped\n",
    "print(num_seqs2)\n",
    "\n",
    "#taking 1% of number of sequences for blast n\n",
    "for index,values in sseq_count_series1.iteritems():\n",
    "        if(values < (0.001)*(num_seqs)):\n",
    "                to_remove1.append(index)\n",
    "                other_count1 += values\n",
    "                otherDict1[values] = index\n",
    "\n",
    "#taking 1% of number of sequences for blast x\n",
    "for index,values in sseq_count_series4.iteritems():\n",
    "        if(values < (0.001)*(num_seqs2)):\n",
    "                to_remove2.append(index)\n",
    "                other_count2 += values\n",
    "                otherDict2[values] = index\n",
    "\n",
    "otherAnswer1 = []\n",
    "increment1 = 0\n",
    "for key,value in sorted(otherDict1.items(),reverse=True):\n",
    "        if increment1 <= 2:\n",
    "                otherAnswer1.append((key,value))\n",
    "                increment1+=1\n",
    "        else:\n",
    "             break              \n",
    "                \n",
    "otherAnswer2 = []\n",
    "increment2 = 0\n",
    "for key,value in sorted(otherDict2.items(),reverse=True):\n",
    "        if increment2 <= 2:\n",
    "                otherAnswer2.append((key,value))\n",
    "                increment2+=1\n",
    "        else:\n",
    "             break\n",
    "\n",
    "gene_ratios = []\n",
    "gene_labels = []  \n",
    "gene_labels_raw = []  \n",
    "\n",
    "for idx in range(len(otherAnswer1)):\n",
    "        gene_ratios.append(otherAnswer1[idx][0]/other_count1)\n",
    "        gene_labels_raw.append(otherAnswer1[idx][1])\n",
    "\n",
    "          \n",
    "                \n",
    "gene_ratios2 = []\n",
    "gene_labels2 = []\n",
    "gene_labels_raw2 = []\n",
    "\n",
    "for idx in range(len(otherAnswer2)):\n",
    "        gene_ratios2.append(otherAnswer2[idx][0]/other_count2)\n",
    "        gene_labels_raw2.append(otherAnswer2[idx][1])\n",
    "\n",
    "\n",
    "\n",
    "#remove these elements from series\n",
    "sseq_count_series2 = sseq_count_series1.drop(to_remove1)\n",
    "sseq_count_series5 = sseq_count_series4.drop(to_remove2)\n",
    "\n",
    "\n",
    "#generate new pandas series with new element to concatenate with old series\n",
    "d = {'Other':other_count1}\n",
    "ser = pd.Series(data=d, index=['Other'])\n",
    "\n",
    "#append new element\n",
    "sseq_count = sseq_count_series2.append(ser)\n",
    "#print(sseq_count)\n",
    "\n",
    "#value_counts returns a pandas series so convert to a data frame\n",
    "sseq_count_df = pd.DataFrame({'sseqid':sseq_count.index, 'count':sseq_count.values})\n",
    "print(sseq_count_df)\n",
    "\n",
    "count = sseq_count_df['count']\n",
    "sseq = sseq_count_df['sseqid']\n",
    "\n",
    "\n",
    "\n",
    "sseq_name_list2 = []\n",
    "sseqid2 = []\n",
    "\n",
    "#generate new pandas series with new element to concatenate with old series\n",
    "d2 = {'Other':other_count2}\n",
    "ser2 = pd.Series(data=d2, index=['Other'])\n",
    "\n",
    "#append new element\n",
    "sseq_count2 = sseq_count_series5.append(ser2)\n",
    "#print(sseq_count)\n",
    "\n",
    "#value_counts returns a pandas series so convert to a data frame\n",
    "sseq_count_df2 = pd.DataFrame({'sseqid':sseq_count2.index, 'count':sseq_count2.values})\n",
    "print(sseq_count_df2)\n",
    "\n",
    "count2 = sseq_count_df2['count']\n",
    "sseq2 = sseq_count_df2['sseqid']\n",
    "\n",
    "\n",
    "bottom = 1\n",
    "width = 0.2\n",
    "\n",
    "wedges1, *_ = ax1.pie(count, labels = sseq, colors=None,autopct='%1.1f%%',startangle=45,\n",
    "        wedgeprops={\"linewidth\": 1, \"edgecolor\": \"white\"})\n",
    "\n",
    "for j, (height, label) in enumerate(reversed([*zip(gene_ratios, gene_labels)])):\n",
    "    bottom -= height\n",
    "    bc = ax2.bar(0, height, width, bottom=bottom, color='C0', label=label,\n",
    "                 alpha=0.1 + 0.25 * j)\n",
    "    ax2.bar_label(bc, labels=[f\"{height:.0%}\"], label_type='center')\n",
    "\n",
    "# ax2.set_title('Other unmapped reads')\n",
    "ax2.legend()\n",
    "ax2.axis('off')\n",
    "ax2.set_xlim(- 2.5 * 2, 2.5 * 2)\n",
    "\n",
    "\n",
    "\n",
    "bottom = 1\n",
    "width = 0.2\n",
    "\n",
    "wedges2, *_ = ax3.pie(count2, labels = sseq2, colors=None,autopct='%1.1f%%',startangle=45,\n",
    "        wedgeprops={\"linewidth\": 1, \"edgecolor\": \"white\"})\n",
    "\n",
    "for j, (height, label) in enumerate(reversed([*zip(gene_ratios2, gene_labels2)])):\n",
    "    bottom -= height\n",
    "    bc = ax4.bar(0, height, width, bottom=bottom, color='C0', label=label,\n",
    "                 alpha=0.1 + 0.25 * j)\n",
    "    ax4.bar_label(bc, labels=[f\"{height:.0%}\"], label_type='center')\n",
    "    \n",
    "# ax4.set_title('Other unmapped reads')\n",
    "ax4.legend()\n",
    "ax4.axis('off')\n",
    "ax4.set_xlim(- 2.5 * 2, 2.5 * 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Get the percentage of the the blast n/x mapped results\n",
    "# for ax5\n",
    "ax5_percentages = [10000000 - num_seqs, num_seqs]\n",
    "ax5_labels = ['Mapped', 'Unmapped']\n",
    "ax5.pie(ax5_percentages, labels=ax5_labels, autopct='%1.1f%%',\n",
    "       colors=['skyblue', 'gray'], labeldistance=1.1)\n",
    "\n",
    "# for ax6\n",
    "ax6_percentages = [10000000 - num_seqs2, num_seqs2]\n",
    "ax6_labels = ['Mapped', 'Unmapped']\n",
    "ax6.pie(ax6_percentages, labels=ax6_labels, autopct='%1.1f%%',\n",
    "       colors=['skyblue', 'gray'], labeldistance=1.1)\n",
    "\n",
    "# Adding Circle in Pie chart\n",
    "circle1 = plt.Circle((0, 0), radius=0.6, color='white')\n",
    "ax5.add_patch(circle1)\n",
    "circle2 = plt.Circle((0, 0), radius=0.6, color='white')\n",
    "ax6.add_patch(circle2)\n",
    "\n",
    "text1 = str(num_seqs) + \"out of 10000000 sequences no mapping\"\n",
    "text2 = str(num_seqs2) + \"out of 10000000 sequences no mapping\"\n",
    "\n",
    "# plt.title('Blastn and Blastx Unmapped Sequences Summary ' + pieName)\n",
    "ax.text(0.95, 0.95, text1, transform=ax.transAxes, fontsize=14,\n",
    "        verticalalignment='top', bbox=props)\n",
    "ax.text(0.95, 0.05, text2, transform=ax.transAxes, fontsize=14,\n",
    "        verticalalignment='top', bbox=props)\n",
    "\n",
    "fig.tight_layout(rect= (5, 5, 5, 5))\n",
    "plt.subplots_adjust(bottom=1.5, right=1.5, top=1.4)\n",
    "plt.show(block=True)\n",
    "plt.savefig(piePath,format='png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399577ba-472f-4661-9e83-9dd35bb6be9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
