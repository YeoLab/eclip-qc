{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a805150-f7f1-4fed-8ccb-218ce5b57f8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xmltodict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxmltodict\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m minidom\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xmltodict'"
     ]
    }
   ],
   "source": [
    "#select intepreter and change environment to anaconda\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib\n",
    "import xmltodict\n",
    "from xml.dom import minidom\n",
    "import time\n",
    "\n",
    "\n",
    "#handles command line input parameter\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# testing file is from 10,000,000 reads, so mapping percentage is expected to be out of 10 mil\n",
    "blast_tsv_file = 'WT_APEX_TOMM20_4_S38_L004_R1_001_1mil_unmappedblast.tsv'\n",
    "blast_tsv_file2 = 'WT_APEX_TOMM20_4_S38_L004_R1_001_1mil_unmappedblast.tsv'\n",
    "piePath = 'Combined.png'\n",
    "piePathSample = os.path.splitext(piePath)[0]\n",
    "piePathSample2 = os.path.split(piePathSample)\n",
    "pieName = piePathSample2[1]\n",
    "\n",
    "#ncbi query functions\n",
    "def esearch(term, db='gds'):\n",
    "    \"\"\"\n",
    "    Queries NCBI using the esearch utility. GEO ('gds') database is used as default for search term.\n",
    "    \"\"\"\n",
    "    url = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db={db}&term={term}&retmax=5000&usehistory=y'\n",
    "    response = urllib.request.urlopen(url)\n",
    "    return response.read()\n",
    "\n",
    "\n",
    "def get_esummary(esearch_string, db='gds'):\n",
    "    \"\"\"\n",
    "    Parses a http response in XML format to obtain the webenv and querykey tokens.\n",
    "    Uses NCBI eutils to transform these tokens into web summaries of GEO (db='gds') datasets.\n",
    "    \"\"\"\n",
    "    xmldoc = minidom.parseString(esearch_string)\n",
    "    try:\n",
    "        webenv = xmldoc.getElementsByTagName('WebEnv')[0].firstChild.data\n",
    "        querykey = xmldoc.getElementsByTagName('QueryKey')[0].firstChild.data\n",
    "        host = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi'\n",
    "        params = f'?db={db}&version=2.0&query_key={querykey}&WebEnv={webenv}'\n",
    "        url = host + params\n",
    "        response = urllib.request.urlopen(url)\n",
    "        return response.read()\n",
    "    except IndexError as e:\n",
    "        print(f\"Unparsable publication string ({e}, search={esearch_string}\")\n",
    "        return \"\"\n",
    "\n",
    "#matplotlib to build the piechart\n",
    "fig, ((ax1, ax2, ax5), (ax3, ax4, ax6)) = plt.subplots(2, 3, figsize=(9, 5))\n",
    "fig.tight_layout(h_pad=2)\n",
    "ax1.set_title('blastn piechart')\n",
    "ax2.set_title('blastn other')\n",
    "ax3.set_title('blastx piechart')\n",
    "ax4.set_title('blastx other')\n",
    "ax5.set_title('blastn percentage')\n",
    "ax6.set_title('blastx percentage')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Read the blast n file\n",
    "df = pd.read_csv(blast_tsv_file, header=None, sep='\\t')\n",
    "num_seqs = df.size\n",
    "df.columns = ['qseqid','sseqid','pident','length','mismatch','gapopen','qstart','qend','sstart','send','evalue','bitscore']\n",
    "\n",
    "df2 = df[['qseqid','sseqid','evalue']].copy()\n",
    "\n",
    "# Read the blast x file\n",
    "df4 = pd.read_csv(blast_tsv_file2, header=None, sep='\\t')\n",
    "num_seqs2 = df4.size\n",
    "df4.columns = ['qseqid','sseqid','pident','length','mismatch','gapopen','qstart','qend','sstart','send','evalue','bitscore']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### still need to reorganize the code for each different file below.\n",
    "\n",
    "\n",
    "#blast n output default is by best hit/lowest e value score, therefore add the first sseqid result for each qseqid\n",
    "sseqid_list1 = []\n",
    "qseqid_list1 = []\n",
    "for idx in df.index:\n",
    "        if df['qseqid'][idx] not in qseqid_list1:\n",
    "                qseqid_list1.append(df['qseqid'][idx])\n",
    "                sseqid_list1.append(df['sseqid'][idx])\n",
    "sseqid_np1 = np.array(sseqid_list1)\n",
    "\n",
    "#blast x output default is by best hit/lowest e value score, therefore add the first sseqid result for each qseqid\n",
    "sseqid_list2 = []\n",
    "qseqid_list2 = []\n",
    "for idx in df4.index:\n",
    "        if df4['qseqid'][idx] not in qseqid_list2:\n",
    "                qseqid_list2.append(df4['qseqid'][idx])\n",
    "                sseqid_list2.append(df4['sseqid'][idx])\n",
    "sseqid_np2 = np.array(sseqid_list2)\n",
    "\n",
    "df3 = pd.DataFrame(data = sseqid_np1, columns=['sseqid'])\n",
    "print(df3)\n",
    "\n",
    "df5 = pd.DataFrame(data = sseqid_np2, columns=['sseqid'])\n",
    "print(df5)\n",
    "\n",
    "sseq_count_series1 = df3['sseqid'].value_counts()\n",
    "print(sseq_count_series1)\n",
    "\n",
    "sseq_count_series4 = df5['sseqid'].value_counts()\n",
    "print(sseq_count_series4)\n",
    "\n",
    "#loop through series to determine which elements to remove and add into \"other\" column\n",
    "to_remove1 = []\n",
    "other_count1 = 0\n",
    "otherDict1 = {}\n",
    "to_remove2 = []\n",
    "other_count2 = 0\n",
    "otherDict2 = {}\n",
    "\n",
    "#blastn number mapped\n",
    "print(num_seqs)\n",
    "\n",
    "#blastx number mapped\n",
    "print(num_seqs2)\n",
    "\n",
    "#taking 1% of number of sequences for blast n\n",
    "for index,values in sseq_count_series1.iteritems():\n",
    "        if(values < (0.001)*(num_seqs)):\n",
    "                to_remove1.append(index)\n",
    "                other_count1 += values\n",
    "                otherDict1[values] = index\n",
    "\n",
    "#taking 1% of number of sequences for blast x\n",
    "for index,values in sseq_count_series4.iteritems():\n",
    "        if(values < (0.001)*(num_seqs2)):\n",
    "                to_remove2.append(index)\n",
    "                other_count2 += values\n",
    "                otherDict2[values] = index\n",
    "\n",
    "otherAnswer1 = []\n",
    "increment1 = 0\n",
    "for key,value in sorted(otherDict1.items(),reverse=True):\n",
    "        if increment1 <= 2:\n",
    "                otherAnswer1.append((key,value))\n",
    "                increment1+=1\n",
    "        else:\n",
    "             break              \n",
    "                \n",
    "otherAnswer2 = []\n",
    "increment2 = 0\n",
    "for key,value in sorted(otherDict2.items(),reverse=True):\n",
    "        if increment2 <= 2:\n",
    "                otherAnswer2.append((key,value))\n",
    "                increment2+=1\n",
    "        else:\n",
    "             break\n",
    "\n",
    "gene_ratios = []\n",
    "gene_labels = []  \n",
    "gene_labels_raw = []  \n",
    "\n",
    "for idx in range(len(otherAnswer1)):\n",
    "        gene_ratios.append(otherAnswer1[idx][0]/other_count1)\n",
    "        gene_labels_raw.append(otherAnswer1[idx][1])\n",
    "\n",
    "#replace index sseqids with ncbi name\n",
    "for idx in range(len(gene_labels_raw)):\n",
    "        term = str(gene_labels_raw[idx])\n",
    "        print(term)\n",
    "        esearch_string = esearch(term=term, db='nucleotide')\n",
    "        time.sleep(0.1)\n",
    "        result = get_esummary(esearch_string=esearch_string, db='nucleotide')\n",
    "        result = xmltodict.parse(result)\n",
    "        sseq_name = result['eSummaryResult']['DocumentSummarySet']['DocumentSummary']['Title']\n",
    "        gene_labels.append(sseq_name)                          \n",
    "                \n",
    "gene_ratios2 = []\n",
    "gene_labels2 = []\n",
    "gene_labels_raw2 = []\n",
    "\n",
    "for idx in range(len(otherAnswer2)):\n",
    "        gene_ratios2.append(otherAnswer2[idx][0]/other_count2)\n",
    "        gene_labels_raw2.append(otherAnswer2[idx][1])\n",
    "\n",
    "#replace index sseqids with ncbi name\n",
    "for idx in range(len(gene_labels_raw2)):\n",
    "        term = str(gene_labels_raw2[idx])\n",
    "        print(term)\n",
    "        esearch_string = esearch(term=term, db='nucleotide')\n",
    "        time.sleep(0.1)\n",
    "        result = get_esummary(esearch_string=esearch_string, db='nucleotide')\n",
    "        result = xmltodict.parse(result)\n",
    "        sseq_name = result['eSummaryResult']['DocumentSummarySet']['DocumentSummary']['Title']\n",
    "        gene_labels2.append(sseq_name) \n",
    "               \n",
    "                \n",
    "\n",
    "#remove these elements from series\n",
    "sseq_count_series2 = sseq_count_series1.drop(to_remove1)\n",
    "sseq_count_series5 = sseq_count_series4.drop(to_remove2)\n",
    "\n",
    "sseq_name_list = []\n",
    "sseqid = []\n",
    "#replace index sseqids with ncbi name\n",
    "for index,values in sseq_count_series2.iteritems():\n",
    "        sseqid.append(index)\n",
    "        term = str(index)\n",
    "        esearch_string = esearch(term=term, db='nucleotide')\n",
    "        time.sleep(0.1)\n",
    "        result = get_esummary(esearch_string=esearch_string, db='nucleotide')\n",
    "        result = xmltodict.parse(result)\n",
    "        sseq_name = result['eSummaryResult']['DocumentSummarySet']['DocumentSummary']['Title']\n",
    "        sseq_name_list.append(sseq_name)\n",
    "        #sseq_count_series2.rename(index={index:sseq_name})\n",
    "#replace the sseqids with ncbi query names\n",
    "replacements = {sseqid:sseq_name_list for sseqid, sseq_name_list in zip(sseqid, sseq_name_list)}\n",
    "sseq_count_series3 = sseq_count_series2.rename(replacements)\n",
    "#sseq_count_series2 = sseq_count_series2.rename(index=dict(zip(sseq_name_list,sseqid)))\n",
    "\n",
    "#generate new pandas series with new element to concatenate with old series\n",
    "d = {'Other':other_count1}\n",
    "ser = pd.Series(data=d, index=['Other'])\n",
    "\n",
    "#append new element\n",
    "sseq_count = sseq_count_series3.append(ser)\n",
    "#print(sseq_count)\n",
    "\n",
    "#value_counts returns a pandas series so convert to a data frame\n",
    "sseq_count_df = pd.DataFrame({'sseqid':sseq_count.index, 'count':sseq_count.values})\n",
    "print(sseq_count_df)\n",
    "\n",
    "count = sseq_count_df['count']\n",
    "sseq = sseq_count_df['sseqid']\n",
    "\n",
    "\n",
    "\n",
    "sseq_name_list2 = []\n",
    "sseqid2 = []\n",
    "#replace index sseqids with ncbi name\n",
    "for index,values in sseq_count_series5.iteritems():\n",
    "        sseqid2.append(index)\n",
    "        term = str(index)\n",
    "        esearch_string = esearch(term=term, db='nucleotide')\n",
    "        time.sleep(0.1)\n",
    "        result = get_esummary(esearch_string=esearch_string, db='nucleotide')\n",
    "        result = xmltodict.parse(result)\n",
    "        sseq_name = result['eSummaryResult']['DocumentSummarySet']['DocumentSummary']['Title']\n",
    "        sseq_name_list2.append(sseq_name)\n",
    "        #sseq_count_series2.rename(index={index:sseq_name})\n",
    "#replace the sseqids with ncbi query names\n",
    "replacements2 = {sseqid2:sseq_name_list2 for sseqid2, sseq_name_list2 in zip(sseqid2, sseq_name_list2)}\n",
    "sseq_count_series6 = sseq_count_series5.rename(replacements2)\n",
    "#sseq_count_series2 = sseq_count_series2.rename(index=dict(zip(sseq_name_list,sseqid)))\n",
    "\n",
    "#generate new pandas series with new element to concatenate with old series\n",
    "d2 = {'Other':other_count2}\n",
    "ser2 = pd.Series(data=d2, index=['Other'])\n",
    "\n",
    "#append new element\n",
    "sseq_count2 = sseq_count_series6.append(ser2)\n",
    "#print(sseq_count)\n",
    "\n",
    "#value_counts returns a pandas series so convert to a data frame\n",
    "sseq_count_df2 = pd.DataFrame({'sseqid':sseq_count2.index, 'count':sseq_count2.values})\n",
    "print(sseq_count_df2)\n",
    "\n",
    "count2 = sseq_count_df2['count']\n",
    "sseq2 = sseq_count_df2['sseqid']\n",
    "\n",
    "\n",
    "bottom = 1\n",
    "width = 0.2\n",
    "\n",
    "wedges1, *_ = ax1.pie(count, labels = sseq, colors=None,autopct='%1.1f%%',startangle=45,\n",
    "        wedgeprops={\"linewidth\": 1, \"edgecolor\": \"white\"})\n",
    "\n",
    "for j, (height, label) in enumerate(reversed([*zip(gene_ratios, gene_labels)])):\n",
    "    bottom -= height\n",
    "    bc = ax2.bar(0, height, width, bottom=bottom, color='C0', label=label,\n",
    "                 alpha=0.1 + 0.25 * j)\n",
    "    ax2.bar_label(bc, labels=[f\"{height:.0%}\"], label_type='center')\n",
    "\n",
    "# ax2.set_title('Other unmapped reads')\n",
    "ax2.legend()\n",
    "ax2.axis('off')\n",
    "ax2.set_xlim(- 2.5 * 2, 2.5 * 2)\n",
    "\n",
    "\n",
    "\n",
    "bottom = 1\n",
    "width = 0.2\n",
    "\n",
    "wedges2, *_ = ax3.pie(count2, labels = sseq2, colors=None,autopct='%1.1f%%',startangle=45,\n",
    "        wedgeprops={\"linewidth\": 1, \"edgecolor\": \"white\"})\n",
    "\n",
    "for j, (height, label) in enumerate(reversed([*zip(gene_ratios2, gene_labels2)])):\n",
    "    bottom -= height\n",
    "    bc = ax4.bar(0, height, width, bottom=bottom, color='C0', label=label,\n",
    "                 alpha=0.1 + 0.25 * j)\n",
    "    ax4.bar_label(bc, labels=[f\"{height:.0%}\"], label_type='center')\n",
    "    \n",
    "# ax4.set_title('Other unmapped reads')\n",
    "ax4.legend()\n",
    "ax4.axis('off')\n",
    "ax4.set_xlim(- 2.5 * 2, 2.5 * 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Get the percentage of the the blast n/x mapped results\n",
    "# for ax5\n",
    "ax5_percentages = [10000000 - num_seqs, num_seqs]\n",
    "ax5_labels = ['Mapped', 'Unmapped']\n",
    "ax5.pie(ax5_percentages, labels=ax5_labels, autopct='%1.1f%%',\n",
    "       colors=['skyblue', 'gray'], labeldistance=1.1)\n",
    "\n",
    "# for ax6\n",
    "ax6_percentages = [10000000 - num_seqs2, num_seqs2]\n",
    "ax6_labels = ['Mapped', 'Unmapped']\n",
    "ax6.pie(ax6_percentages, labels=ax6_labels, autopct='%1.1f%%',\n",
    "       colors=['skyblue', 'gray'], labeldistance=1.1)\n",
    "\n",
    "# Adding Circle in Pie chart\n",
    "circle1 = plt.Circle((0, 0), radius=0.6, color='white')\n",
    "ax5.add_patch(circle1)\n",
    "circle2 = plt.Circle((0, 0), radius=0.6, color='white')\n",
    "ax6.add_patch(circle2)\n",
    "\n",
    "text1 = str(num_seqs) + \"out of 10000000 sequences no mapping\"\n",
    "text2 = str(num_seqs2) + \"out of 10000000 sequences no mapping\"\n",
    "\n",
    "# plt.title('Blastn and Blastx Unmapped Sequences Summary ' + pieName)\n",
    "ax.text(0.95, 0.95, text1, transform=ax.transAxes, fontsize=14,\n",
    "        verticalalignment='top', bbox=props)\n",
    "ax.text(0.95, 0.05, text2, transform=ax.transAxes, fontsize=14,\n",
    "        verticalalignment='top', bbox=props)\n",
    "\n",
    "fig.tight_layout(rect= (5, 5, 5, 5))\n",
    "plt.subplots_adjust(bottom=1.5, right=1.5, top=1.4)\n",
    "plt.show(block=True)\n",
    "plt.savefig(piePath,format='png',bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fec6f44-294f-4727-bb78-d106b12240e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
